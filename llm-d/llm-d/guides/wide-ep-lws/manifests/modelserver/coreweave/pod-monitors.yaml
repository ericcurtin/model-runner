apiVersion: monitoring.coreos.com/v1
kind: PodMonitor
metadata:
  name: ms-wide-ep-llm-d-modelservice-decode-podmonitor
  labels:
    llm-d.ai/inferenceServing: "true"
    llm-d.ai/model: DeepSeek-R1-0528
    llm-d.ai/role: decode
spec:
  selector:
    matchLabels:
      llm-d.ai/inferenceServing: "true"
      llm-d.ai/model: DeepSeek-R1-0528
      llm-d.ai/role: decode
  podMetricsEndpoints:
  # For decode service, this is port 8200. Must use port name.
  - port: "metrics"
    path: /metrics
    interval: 5s
---
# Source: llm-d-modelservice/templates/prefill-podmonitor.yaml
apiVersion: monitoring.coreos.com/v1
kind: PodMonitor
metadata:
  name: ms-wide-ep-llm-d-modelservice-prefill-podmonitor
  labels:
    llm-d.ai/inferenceServing: "true"
    llm-d.ai/model: DeepSeek-R1-0528
    llm-d.ai/role: prefill
spec:
  selector:
    matchLabels:
      llm-d.ai/inferenceServing: "true"
      llm-d.ai/model: DeepSeek-R1-0528
      llm-d.ai/role: prefill
  podMetricsEndpoints:
  # For prefill, this is port 8000. Must use port name.
  - port: "metrics"
    path: /metrics
    interval: 5s
