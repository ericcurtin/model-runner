apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization
resources:
  - ../base
  - pod-monitors.yaml
patches:
  - target:
      kind: LeaderWorkerSet
    patch: |-
      # We add the volume for different providers since the hostPath can be different.
      - op: add
        path: /spec/leaderWorkerTemplate/workerTemplate/spec/volumes/-
        value: 
          name: hf-cache
          hostPath:
            path: /mnt/local/hf-cache
            type: DirectoryOrCreate
      # Since we are loading model in from a host storage, lets patch in the volumeMount
      - op: add
        path: /spec/leaderWorkerTemplate/workerTemplate/spec/containers/0/volumeMounts/-
        value:
          name: hf-cache
          mountPath: /huggingface-cache
      # Since we are loading model in from a host storage, specify HF_HUB_CACHE
      - op: add
        path: /spec/leaderWorkerTemplate/workerTemplate/spec/containers/0/env/-
        value:
          name: HF_HUB_CACHE
          value: /huggingface-cache
      # Since we are loading model in from a host storage, disable HF_XET
      - op: add
        path: /spec/leaderWorkerTemplate/workerTemplate/spec/containers/0/env/-
        value:
          name: HF_HUB_DISABLE_XET
          value: "1"
      - op: add
        path: /spec/leaderWorkerTemplate/workerTemplate/spec/containers/0/env/-
        value:
          name: NCCL_IB_HCA
          value: "ibp"
      # TODO: Remove this once we have the llm-d image working on GKE.
      - op: add
        path: /spec/leaderWorkerTemplate/workerTemplate/spec/containers/0/env/-
        value:
          name: VENV_PATH
          value: "/opt/vllm"
      # Add RMDA config.
      - op: add
        path: /spec/leaderWorkerTemplate/workerTemplate/spec/containers/0/resources/limits/rdma~1ib
        value: "1"
      - op: add
        path: /spec/leaderWorkerTemplate/workerTemplate/spec/containers/0/resources/requests/rdma~1ib
        value: "1"
      # Add GPU affinity.
      - op: add
        path: /spec/leaderWorkerTemplate/workerTemplate/spec/affinity
        value:
          nodeAffinity:
            requiredDuringSchedulingIgnoredDuringExecution:
              nodeSelectorTerms:
                - matchExpressions:
                  - key: gpu.nvidia.com/model
                    operator: In
                    values:
                      - H200
      - op: add
        path: /spec/leaderWorkerTemplate/workerTemplate/spec/schedulerName
        value: custom-binpack-scheduler
