apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization
resources:
  - ../base
patches:
  - target:
      kind: LeaderWorkerSet
      name: wide-ep-llm-d-prefill
    patch: |-
      # Prefer the same block and subblock.
      # https://github.com/llm-d/llm-d/tree/main/docs/infra-providers/gke#configuring-support-for-rdma-on-gke-workload-pods
      - op: add
        path: /spec/leaderWorkerTemplate/workerTemplate/spec/affinity
        value:
          podAffinity:
            # Subblock affinity cannot guarantee all pods in the replica
            # are in the same subblock, but is better than random spreading
            preferredDuringSchedulingIgnoredDuringExecution:
            - weight: 2
              podAffinityTerm:
                labelSelector:
                  matchLabels:
                    llm-d.ai/role: prefill
                matchLabelKeys:
                - component
                topologyKey: cloud.google.com/gce-topology-block
            - weight: 1
              podAffinityTerm:
                labelSelector:
                  matchLabels:
                    llm-d.ai/role: prefill
                matchLabelKeys:
                - component
                topologyKey: cloud.google.com/gce-topology-subblock
  - target:
      kind: LeaderWorkerSet
      name: wide-ep-llm-d-decode
    patch: |-
      # Prefer the same block and subblock.
      # https://github.com/llm-d/llm-d/tree/main/docs/infra-providers/gke#configuring-support-for-rdma-on-gke-workload-pods
      - op: add
        path: /spec/leaderWorkerTemplate/workerTemplate/spec/affinity
        value:
          podAffinity:
            # Subblock affinity cannot guarantee all pods in the replica
            # are in the same subblock, but is better than random spreading
            preferredDuringSchedulingIgnoredDuringExecution:
            - weight: 2
              podAffinityTerm:
                labelSelector:
                  matchLabels:
                    llm-d.ai/role: decode
                matchLabelKeys:
                - component
                topologyKey: cloud.google.com/gce-topology-block
            - weight: 1
              podAffinityTerm:
                labelSelector:
                  matchLabels:
                    llm-d.ai/role: decode
                matchLabelKeys:
                - component
                topologyKey: cloud.google.com/gce-topology-subblock
  # Common configurations for prefill and decode.
  - target:
      kind: LeaderWorkerSet
    patch: |-
      # Enable privileged container  on GKE to perform GPU initiated RDMA.
      # See https://github.com/llm-d/llm-d/tree/main/docs/infra-providers/gke#configuring-support-for-rdma-on-gke-workload-pods.
      - op: add
        path: /spec/leaderWorkerTemplate/workerTemplate/spec/containers/0/securityContext/privileged
        value: true
      # Add GKE specific RDMA configuration.
      - op: add
        path: /spec/leaderWorkerTemplate/workerTemplate/metadata/annotations
        value:
          networking.gke.io/default-interface: 'eth0'
          networking.gke.io/interfaces: |
            [
              {"interfaceName":"eth0","network":"default"},
              {"interfaceName":"eth2","network":"rdma-0"},
              {"interfaceName":"eth3","network":"rdma-1"},
              {"interfaceName":"eth4","network":"rdma-2"},
              {"interfaceName":"eth5","network":"rdma-3"},
              {"interfaceName":"eth6","network":"rdma-4"},
              {"interfaceName":"eth7","network":"rdma-5"},
              {"interfaceName":"eth8","network":"rdma-6"},
              {"interfaceName":"eth9","network":"rdma-7"}
            ]
      # Add GKE gib per https://cloud.google.com/ai-hypercomputer/docs/create/gke-ai-hypercompute-custom#configure-pod-manifests-rdma
      - op: add
        path: /spec/leaderWorkerTemplate/workerTemplate/spec/volumes/-
        value:
          name: gib
          hostPath:
            path: /home/kubernetes/bin/gib
            type: ""
      - op: add
        path: /spec/leaderWorkerTemplate/workerTemplate/spec/containers/0/volumeMounts/-
        value:
          mountPath: /usr/local/gib
          name: gib
      # Env vars 
      - op: add
        path: /spec/leaderWorkerTemplate/workerTemplate/spec/containers/0/env/-
        value:
          # GCP pairs GPU NICs to PCIe bridges (https://cloud.google.com/compute/docs/gpus/gpu-network-bandwidth#h200-gpus),
          # which can lead to NVSHMEM's automatic distance assignment algorithm selecting NICs
          # inefficiently. Instead, instruct NVSHMEM to select the NIC that aligns to the
          # index of the GPU on the node.
          name: NVSHMEM_ENABLE_NIC_PE_MAPPING
          value: "1"
      - op: add
        path: /spec/leaderWorkerTemplate/workerTemplate/spec/containers/0/env/-
        value:
          name: NVSHMEM_HCA_LIST
          value: "mlx5_0:1,mlx5_1:1,mlx5_2:1,mlx5_3:1,mlx5_4:1,mlx5_5:1,mlx5_6:1,mlx5_7:1"
      # https://cloud.google.com/ai-hypercomputer/docs/create/gke-ai-hypercompute-custom#configure-pod-manifests-rdma
      - op: add
        path: /spec/leaderWorkerTemplate/workerTemplate/spec/containers/0/env/-
        value:
          name: LD_LIBRARY_PATH
          value: "/usr/local/nvidia/lib64"
      # Source nccl env at startup.
      # https://cloud.google.com/ai-hypercomputer/docs/create/gke-ai-hypercompute-custom#configure-pod-manifests-rdma
      - op: add
        path: /spec/leaderWorkerTemplate/workerTemplate/spec/containers/0/env/-
        value:
          name: BASH_ENV
          value: "/usr/local/gib/scripts/set_nccl_env.sh"
      # Disable GCP NCCL telemetry due to failures to upload blocking
      - op: add
        path: /spec/leaderWorkerTemplate/workerTemplate/spec/containers/0/env/-
        value:
          name: NCCL_TELEMETRY_MODE
          value: "0"
      # This is recommended on gke.
      # https://github.com/llm-d/llm-d/tree/main/docs/infra-providers/gke#configuring-support-for-rdma-on-gke-workload-pods
      - op: add
        path: /spec/leaderWorkerTemplate/workerTemplate/spec/containers/0/env/-
        value:
          name: NVSHMEM_DISABLED_GDRCOPY
          value: "true"
      # TODO: Remove this once we have the llm-d image working on GKE.
      - op: add
        path: /spec/leaderWorkerTemplate/workerTemplate/spec/containers/0/env/-
        value:
          name: VENV_PATH
          value: "/app/venv"
      # Override the image to be the GKE workaround image.
      # TODO: Remove this once we have the llm-d image working on GKE.
      # Replace container image
      - op: replace
        path: /spec/leaderWorkerTemplate/workerTemplate/spec/containers/0/image
        value: ghcr.io/llm-d/llm-d-gke:v0.3.0
