openapi: 3.0.3
info:
  title: Docker Model Runner API
  description: |
    Docker Model Runner provides a unified API for running AI models locally. 
    It supports multiple API formats including OpenAI-compatible, Anthropic-compatible, and Ollama-compatible APIs.
    
    ## API Compatibility Layers
    
    - **OpenAI API** - Full compatibility with OpenAI's chat completions, completions, and embeddings endpoints
    - **Anthropic API** - Compatible with Anthropic's Messages API format
    - **Ollama API** - Compatible with Ollama's chat, generate, and model management endpoints
    
    ## Getting Started
    
    1. Pull a model: `docker model pull ai/smollm2:latest`
    2. Start making API requests to any of the supported endpoints
  version: "1.0.0"
  contact:
    name: Docker
    url: https://github.com/docker/model-runner
  license:
    name: Apache 2.0
    url: https://www.apache.org/licenses/LICENSE-2.0

servers:
  - url: /
    description: Local Model Runner

tags:
  - name: OpenAI API
    description: OpenAI-compatible API endpoints for chat completions, completions, and embeddings
  - name: Anthropic API
    description: Anthropic-compatible Messages API
  - name: Ollama API
    description: Ollama-compatible API for model management and inference
  - name: Models
    description: Model management endpoints
  - name: System
    description: System status and management endpoints

paths:
  # OpenAI API Endpoints
  /v1/chat/completions:
    post:
      tags:
        - OpenAI API
      summary: Create chat completion
      description: Creates a chat completion for the provided messages using the specified model
      operationId: createChatCompletion
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ChatCompletionRequest'
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ChatCompletionResponse'
            text/event-stream:
              schema:
                type: string
                description: Server-sent events stream for streaming responses
        '400':
          description: Bad request
        '404':
          description: Model not found

  /v1/completions:
    post:
      tags:
        - OpenAI API
      summary: Create completion
      description: Creates a completion for the provided prompt using the specified model
      operationId: createCompletion
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CompletionRequest'
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/CompletionResponse'
        '400':
          description: Bad request
        '404':
          description: Model not found

  /v1/embeddings:
    post:
      tags:
        - OpenAI API
      summary: Create embeddings
      description: Creates an embedding vector representing the input text
      operationId: createEmbedding
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/EmbeddingRequest'
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/EmbeddingResponse'
        '400':
          description: Bad request
        '404':
          description: Model not found

  /v1/models:
    get:
      tags:
        - OpenAI API
        - Models
      summary: List models
      description: Lists the currently available models in OpenAI format
      operationId: listModelsOpenAI
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/OpenAIModelList'

  /v1/models/{model}:
    get:
      tags:
        - OpenAI API
        - Models
      summary: Get model details
      description: Retrieves details about a specific model
      operationId: getModelOpenAI
      parameters:
        - name: model
          in: path
          required: true
          schema:
            type: string
          description: The model identifier
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/OpenAIModel'
        '404':
          description: Model not found

  # OpenAI Responses API
  /responses:
    post:
      tags:
        - OpenAI API
      summary: Create a response
      description: |
        Creates a response using the Responses API. The Responses API is a stateful API that 
        combines chat completions with conversation state management and tool use capabilities.
      operationId: createResponse
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ResponsesRequest'
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ResponsesResponse'
            text/event-stream:
              schema:
                type: string
                description: Server-sent events stream for streaming responses
        '400':
          description: Bad request
        '404':
          description: Model not found

  /responses/{response_id}:
    get:
      tags:
        - OpenAI API
      summary: Get a response
      description: Retrieves a previously created response by ID
      operationId: getResponse
      parameters:
        - name: response_id
          in: path
          required: true
          schema:
            type: string
          description: The response ID
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ResponsesResponse'
        '404':
          description: Response not found

  # Anthropic API Endpoints
  /anthropic/v1/messages:
    post:
      tags:
        - Anthropic API
      summary: Create a message
      description: |
        Creates a message using the Anthropic Messages API format.
        This endpoint is compatible with Anthropic's Claude API.
      operationId: createAnthropicMessage
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/AnthropicMessagesRequest'
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/AnthropicMessagesResponse'
            text/event-stream:
              schema:
                type: string
                description: Server-sent events stream for streaming responses
        '400':
          description: Bad request - invalid_request_error
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/AnthropicError'
        '404':
          description: Model not found - not_found_error
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/AnthropicError'

  /anthropic/v1/messages/count_tokens:
    post:
      tags:
        - Anthropic API
      summary: Count tokens
      description: Count the number of tokens in a message
      operationId: countAnthropicTokens
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/AnthropicMessagesRequest'
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/AnthropicTokenCount'
        '400':
          description: Bad request
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/AnthropicError'

  # Ollama API Endpoints
  /api/chat:
    post:
      tags:
        - Ollama API
      summary: Chat with a model
      description: |
        Generate a chat completion response for a given conversation.
        This is Ollama's primary chat interface.
      operationId: ollamaChat
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/OllamaChatRequest'
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/OllamaChatResponse'
            application/x-ndjson:
              schema:
                $ref: '#/components/schemas/OllamaChatResponse'
        '400':
          description: Bad request
        '404':
          description: Model not found

  /api/generate:
    post:
      tags:
        - Ollama API
      summary: Generate a completion
      description: |
        Generate a text completion for a given prompt.
        Supports streaming responses.
      operationId: ollamaGenerate
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/OllamaGenerateRequest'
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/OllamaGenerateResponse'
            application/x-ndjson:
              schema:
                $ref: '#/components/schemas/OllamaGenerateResponse'
        '400':
          description: Bad request
        '404':
          description: Model not found

  /api/tags:
    get:
      tags:
        - Ollama API
      summary: List local models
      description: Lists all locally available models in Ollama format
      operationId: ollamaListModels
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/OllamaListResponse'

  /api/show:
    post:
      tags:
        - Ollama API
      summary: Show model information
      description: Shows detailed information about a specific model
      operationId: ollamaShowModel
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/OllamaShowRequest'
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/OllamaShowResponse'
        '404':
          description: Model not found

  /api/pull:
    post:
      tags:
        - Ollama API
      summary: Pull a model
      description: |
        Downloads a model from the registry.
        Returns streaming progress updates.
      operationId: ollamaPullModel
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/OllamaPullRequest'
      responses:
        '200':
          description: Successful response with streaming progress
          content:
            application/x-ndjson:
              schema:
                $ref: '#/components/schemas/OllamaPullStatus'

  /api/delete:
    delete:
      tags:
        - Ollama API
      summary: Delete a model
      description: Deletes a model from local storage
      operationId: ollamaDeleteModel
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/OllamaDeleteRequest'
      responses:
        '200':
          description: Model deleted successfully
        '404':
          description: Model not found

  /api/ps:
    get:
      tags:
        - Ollama API
      summary: List running models
      description: Shows which models are currently loaded in memory
      operationId: ollamaPS
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/OllamaPSResponse'

  /api/version:
    get:
      tags:
        - Ollama API
      summary: Get version
      description: Returns the Ollama-compatible API version
      operationId: ollamaVersion
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                type: object
                properties:
                  version:
                    type: string
                    example: "0.1.0"

  # Model Management Endpoints
  /models:
    get:
      tags:
        - Models
      summary: List all models
      description: Lists all locally available models
      operationId: listModels
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                type: array
                items:
                  $ref: '#/components/schemas/ModelInfo'

  /models/{model}:
    get:
      tags:
        - Models
      summary: Get model information
      description: Get detailed information about a specific model
      operationId: getModel
      parameters:
        - name: model
          in: path
          required: true
          schema:
            type: string
          description: The model identifier
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ModelInfo'
        '404':
          description: Model not found

    delete:
      tags:
        - Models
      summary: Delete a model
      description: Deletes a model from local storage
      operationId: deleteModel
      parameters:
        - name: model
          in: path
          required: true
          schema:
            type: string
          description: The model identifier
      responses:
        '200':
          description: Model deleted successfully
        '404':
          description: Model not found

  # System Endpoints
  /engines/status:
    get:
      tags:
        - System
      summary: Get backend status
      description: Returns the status of all inference backends
      operationId: getBackendStatus
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                type: object
                additionalProperties:
                  type: string
                example:
                  "llama.cpp": "ready"

  /engines/ps:
    get:
      tags:
        - System
      summary: Get running backends
      description: Returns information about running backend instances
      operationId: getRunningBackends
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                type: array
                items:
                  $ref: '#/components/schemas/BackendStatus'

  /engines/df:
    get:
      tags:
        - System
      summary: Get disk usage
      description: Returns disk usage information for models and backends
      operationId: getDiskUsage
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/DiskUsage'

  /engines/unload:
    post:
      tags:
        - System
      summary: Unload models
      description: Unloads specified models from memory
      operationId: unloadModels
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/UnloadRequest'
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/UnloadResponse'

  /metrics:
    get:
      tags:
        - System
      summary: Get Prometheus metrics
      description: Returns Prometheus-format metrics for monitoring
      operationId: getMetrics
      responses:
        '200':
          description: Successful response
          content:
            text/plain:
              schema:
                type: string

components:
  schemas:
    # OpenAI API Schemas
    ChatCompletionRequest:
      type: object
      required:
        - model
        - messages
      properties:
        model:
          type: string
          description: ID of the model to use
          example: "ai/smollm2:latest"
        messages:
          type: array
          description: A list of messages comprising the conversation
          items:
            $ref: '#/components/schemas/ChatMessage'
        temperature:
          type: number
          minimum: 0
          maximum: 2
          default: 1
          description: Sampling temperature
        top_p:
          type: number
          minimum: 0
          maximum: 1
          default: 1
          description: Nucleus sampling probability
        max_tokens:
          type: integer
          description: Maximum number of tokens to generate
        stream:
          type: boolean
          default: false
          description: Whether to stream partial responses
        stop:
          oneOf:
            - type: string
            - type: array
              items:
                type: string
          description: Stop sequences
        presence_penalty:
          type: number
          minimum: -2
          maximum: 2
          default: 0
        frequency_penalty:
          type: number
          minimum: -2
          maximum: 2
          default: 0
        tools:
          type: array
          items:
            $ref: '#/components/schemas/Tool'
          description: A list of tools the model may call
        tool_choice:
          description: Controls which tool is called by the model
          oneOf:
            - type: string
              enum: [none, auto, required]
            - type: object
              properties:
                type:
                  type: string
                  enum: [function]
                function:
                  type: object
                  properties:
                    name:
                      type: string

    ChatMessage:
      type: object
      required:
        - role
        - content
      properties:
        role:
          type: string
          enum: [system, user, assistant, tool]
          description: The role of the message author
        content:
          oneOf:
            - type: string
            - type: array
              items:
                $ref: '#/components/schemas/ContentPart'
          description: The content of the message
        name:
          type: string
          description: An optional name for the participant
        tool_calls:
          type: array
          items:
            $ref: '#/components/schemas/ToolCall'
        tool_call_id:
          type: string
          description: Tool call ID when role is tool

    ContentPart:
      type: object
      required:
        - type
      properties:
        type:
          type: string
          enum: [text, image_url]
        text:
          type: string
        image_url:
          type: object
          properties:
            url:
              type: string
              description: URL or base64-encoded image

    Tool:
      type: object
      required:
        - type
        - function
      properties:
        type:
          type: string
          enum: [function]
        function:
          $ref: '#/components/schemas/FunctionDefinition'

    FunctionDefinition:
      type: object
      required:
        - name
      properties:
        name:
          type: string
        description:
          type: string
        parameters:
          type: object
          description: JSON Schema for the function parameters

    ToolCall:
      type: object
      properties:
        id:
          type: string
        type:
          type: string
          enum: [function]
        function:
          type: object
          properties:
            name:
              type: string
            arguments:
              type: string

    ChatCompletionResponse:
      type: object
      properties:
        id:
          type: string
        object:
          type: string
          enum: [chat.completion]
        created:
          type: integer
        model:
          type: string
        choices:
          type: array
          items:
            type: object
            properties:
              index:
                type: integer
              message:
                $ref: '#/components/schemas/ChatMessage'
              finish_reason:
                type: string
                enum: [stop, length, tool_calls, content_filter]
        usage:
          $ref: '#/components/schemas/Usage'

    CompletionRequest:
      type: object
      required:
        - model
        - prompt
      properties:
        model:
          type: string
          description: ID of the model to use
        prompt:
          oneOf:
            - type: string
            - type: array
              items:
                type: string
          description: The prompt(s) to generate completions for
        max_tokens:
          type: integer
          default: 16
        temperature:
          type: number
          default: 1
        top_p:
          type: number
          default: 1
        stream:
          type: boolean
          default: false
        stop:
          oneOf:
            - type: string
            - type: array
              items:
                type: string

    CompletionResponse:
      type: object
      properties:
        id:
          type: string
        object:
          type: string
          enum: [text_completion]
        created:
          type: integer
        model:
          type: string
        choices:
          type: array
          items:
            type: object
            properties:
              text:
                type: string
              index:
                type: integer
              finish_reason:
                type: string
        usage:
          $ref: '#/components/schemas/Usage'

    EmbeddingRequest:
      type: object
      required:
        - model
        - input
      properties:
        model:
          type: string
          description: ID of the model to use
          example: "ai/mxbai-embed-large:335M-F16"
        input:
          oneOf:
            - type: string
            - type: array
              items:
                type: string
          description: Input text to embed

    EmbeddingResponse:
      type: object
      properties:
        object:
          type: string
          enum: [list]
        data:
          type: array
          items:
            type: object
            properties:
              object:
                type: string
                enum: [embedding]
              embedding:
                type: array
                items:
                  type: number
              index:
                type: integer
        model:
          type: string
        usage:
          type: object
          properties:
            prompt_tokens:
              type: integer
            total_tokens:
              type: integer

    Usage:
      type: object
      properties:
        prompt_tokens:
          type: integer
        completion_tokens:
          type: integer
        total_tokens:
          type: integer

    OpenAIModelList:
      type: object
      properties:
        object:
          type: string
          enum: [list]
        data:
          type: array
          items:
            $ref: '#/components/schemas/OpenAIModel'

    OpenAIModel:
      type: object
      properties:
        id:
          type: string
        object:
          type: string
          enum: [model]
        created:
          type: integer
        owned_by:
          type: string

    # Responses API Schemas
    ResponsesRequest:
      type: object
      required:
        - model
        - input
      properties:
        model:
          type: string
          description: The model to use
        input:
          description: The input to the model (string or array of input items)
          oneOf:
            - type: string
            - type: array
              items:
                $ref: '#/components/schemas/ResponsesInputItem'
        instructions:
          type: string
          description: System instructions for the model
        previous_response_id:
          type: string
          description: ID of a previous response for conversation chaining
        tools:
          type: array
          items:
            $ref: '#/components/schemas/Tool'
        tool_choice:
          description: Controls tool usage
        temperature:
          type: number
        top_p:
          type: number
        max_output_tokens:
          type: integer
        stream:
          type: boolean
        metadata:
          type: object
          additionalProperties:
            type: string

    ResponsesInputItem:
      type: object
      properties:
        type:
          type: string
        role:
          type: string
        content:
          description: Content (string or array)
        call_id:
          type: string
        output:
          type: string

    ResponsesResponse:
      type: object
      properties:
        id:
          type: string
        object:
          type: string
          enum: [response]
        created_at:
          type: number
        model:
          type: string
        status:
          type: string
          enum: [queued, in_progress, completed, cancelled, failed]
        output:
          type: array
          items:
            $ref: '#/components/schemas/ResponsesOutputItem'
        output_text:
          type: string
        error:
          $ref: '#/components/schemas/ErrorDetail'
        usage:
          $ref: '#/components/schemas/Usage'

    ResponsesOutputItem:
      type: object
      properties:
        id:
          type: string
        type:
          type: string
        role:
          type: string
        content:
          type: array
          items:
            type: object
            properties:
              type:
                type: string
              text:
                type: string
        status:
          type: string

    ErrorDetail:
      type: object
      properties:
        code:
          type: string
        message:
          type: string

    # Anthropic API Schemas
    AnthropicMessagesRequest:
      type: object
      required:
        - model
        - messages
        - max_tokens
      properties:
        model:
          type: string
          description: The model to use
          example: "ai/smollm2:latest"
        messages:
          type: array
          items:
            $ref: '#/components/schemas/AnthropicMessage'
        max_tokens:
          type: integer
          description: Maximum tokens to generate
          example: 1024
        system:
          type: string
          description: System prompt
        temperature:
          type: number
          minimum: 0
          maximum: 1
        top_p:
          type: number
        top_k:
          type: integer
        stream:
          type: boolean
          default: false
        stop_sequences:
          type: array
          items:
            type: string
        metadata:
          type: object
          properties:
            user_id:
              type: string

    AnthropicMessage:
      type: object
      required:
        - role
        - content
      properties:
        role:
          type: string
          enum: [user, assistant]
        content:
          oneOf:
            - type: string
            - type: array
              items:
                $ref: '#/components/schemas/AnthropicContentBlock'

    AnthropicContentBlock:
      type: object
      required:
        - type
      properties:
        type:
          type: string
          enum: [text, image]
        text:
          type: string
        source:
          type: object
          properties:
            type:
              type: string
              enum: [base64]
            media_type:
              type: string
            data:
              type: string

    AnthropicMessagesResponse:
      type: object
      properties:
        id:
          type: string
        type:
          type: string
          enum: [message]
        role:
          type: string
          enum: [assistant]
        content:
          type: array
          items:
            type: object
            properties:
              type:
                type: string
                enum: [text]
              text:
                type: string
        model:
          type: string
        stop_reason:
          type: string
          enum: [end_turn, max_tokens, stop_sequence, tool_use]
        stop_sequence:
          type: string
          nullable: true
        usage:
          type: object
          properties:
            input_tokens:
              type: integer
            output_tokens:
              type: integer

    AnthropicError:
      type: object
      properties:
        type:
          type: string
          enum: [error]
        error:
          type: object
          properties:
            type:
              type: string
              enum: [invalid_request_error, not_found_error, internal_error, request_too_large]
            message:
              type: string

    AnthropicTokenCount:
      type: object
      properties:
        input_tokens:
          type: integer

    # Ollama API Schemas
    OllamaChatRequest:
      type: object
      required:
        - model
        - messages
      properties:
        model:
          type: string
          description: Name of the model to use
          example: "ai/smollm2:latest"
        messages:
          type: array
          items:
            $ref: '#/components/schemas/OllamaMessage'
        stream:
          type: boolean
          default: true
          description: Enable streaming responses
        tools:
          type: array
          items:
            $ref: '#/components/schemas/OllamaTool'
        think:
          description: Enable thinking/reasoning mode (boolean)
          oneOf:
            - type: boolean
        keep_alive:
          type: string
          description: How long to keep model loaded (e.g., "5m", "0s" to unload)
        options:
          type: object
          description: Model-specific options
          properties:
            temperature:
              type: number
            top_p:
              type: number
            top_k:
              type: integer
            num_predict:
              type: integer
              description: Max tokens to generate
            num_ctx:
              type: integer
              description: Context window size
            seed:
              type: integer
            stop:
              type: array
              items:
                type: string

    OllamaMessage:
      type: object
      required:
        - role
        - content
      properties:
        role:
          type: string
          enum: [system, user, assistant, tool]
        content:
          type: string
        images:
          type: array
          items:
            type: string
          description: Base64-encoded images for multimodal models
        tool_calls:
          type: array
          items:
            $ref: '#/components/schemas/OllamaToolCall'
        tool_call_id:
          type: string

    OllamaTool:
      type: object
      properties:
        type:
          type: string
          enum: [function]
        function:
          type: object
          properties:
            name:
              type: string
            description:
              type: string
            parameters:
              type: object

    OllamaToolCall:
      type: object
      properties:
        id:
          type: string
        type:
          type: string
        function:
          type: object
          properties:
            name:
              type: string
            arguments:
              description: Function arguments (string or object)

    OllamaChatResponse:
      type: object
      properties:
        model:
          type: string
        created_at:
          type: string
          format: date-time
        message:
          $ref: '#/components/schemas/OllamaMessage'
        done:
          type: boolean
        done_reason:
          type: string

    OllamaGenerateRequest:
      type: object
      required:
        - model
        - prompt
      properties:
        model:
          type: string
          description: Name of the model to use
        prompt:
          type: string
          description: The prompt to generate a response for
        stream:
          type: boolean
          default: true
        think:
          description: Enable thinking/reasoning mode
          oneOf:
            - type: boolean
        keep_alive:
          type: string
        options:
          type: object
          properties:
            temperature:
              type: number
            top_p:
              type: number
            num_predict:
              type: integer
            num_ctx:
              type: integer

    OllamaGenerateResponse:
      type: object
      properties:
        model:
          type: string
        created_at:
          type: string
          format: date-time
        response:
          type: string
        thinking:
          type: string
          description: Model's thinking output for reasoning models
        done:
          type: boolean

    OllamaListResponse:
      type: object
      properties:
        models:
          type: array
          items:
            $ref: '#/components/schemas/OllamaModelResponse'

    OllamaModelResponse:
      type: object
      properties:
        name:
          type: string
        model:
          type: string
        modified_at:
          type: string
          format: date-time
        size:
          type: integer
        digest:
          type: string
        details:
          $ref: '#/components/schemas/OllamaModelDetails'

    OllamaModelDetails:
      type: object
      properties:
        format:
          type: string
        family:
          type: string
        families:
          type: array
          items:
            type: string
        parameter_size:
          type: string
        quantization_level:
          type: string

    OllamaShowRequest:
      type: object
      properties:
        name:
          type: string
          description: Model name (Ollama format)
        model:
          type: string
          description: Model name (alternative field)
        verbose:
          type: boolean

    OllamaShowResponse:
      type: object
      properties:
        license:
          type: string
        modelfile:
          type: string
        parameters:
          type: string
        template:
          type: string
        details:
          $ref: '#/components/schemas/OllamaModelDetails'

    OllamaPullRequest:
      type: object
      properties:
        name:
          type: string
          description: Model name to pull
        model:
          type: string
          description: Model name (alternative field)
        insecure:
          type: boolean
        stream:
          type: boolean

    OllamaPullStatus:
      type: object
      properties:
        status:
          type: string
        digest:
          type: string
        total:
          type: integer
        completed:
          type: integer
        error:
          type: string

    OllamaDeleteRequest:
      type: object
      properties:
        name:
          type: string
        model:
          type: string

    OllamaPSResponse:
      type: object
      properties:
        models:
          type: array
          items:
            type: object
            properties:
              name:
                type: string
              model:
                type: string
              size:
                type: integer
              digest:
                type: string
              expires_at:
                type: string
                format: date-time
              size_vram:
                type: integer

    # Model Management Schemas
    ModelInfo:
      type: object
      properties:
        id:
          type: string
        tags:
          type: array
          items:
            type: string
        created:
          type: integer
        config:
          type: object
          properties:
            architecture:
              type: string
            parameters:
              type: string
            quantization:
              type: string

    # System Schemas
    BackendStatus:
      type: object
      properties:
        backend_name:
          type: string
        model_name:
          type: string
        mode:
          type: string
          enum: [completion, embedding, reranking]
        last_used:
          type: string
          format: date-time
        in_use:
          type: boolean

    DiskUsage:
      type: object
      properties:
        models_disk_usage:
          type: integer
          description: Disk usage for models in bytes
        default_backend_disk_usage:
          type: integer
          description: Disk usage for the default backend in bytes

    UnloadRequest:
      type: object
      properties:
        all:
          type: boolean
          description: Unload all models
        backend:
          type: string
          description: Specific backend to unload from
        models:
          type: array
          items:
            type: string
          description: Specific models to unload

    UnloadResponse:
      type: object
      properties:
        unloaded_runners:
          type: integer
          description: Number of runners that were unloaded
